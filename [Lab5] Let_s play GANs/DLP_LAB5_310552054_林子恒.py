# -*- coding: utf-8 -*-
"""DLP_LAB5_310552054_林子恒.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1M_MBjwjzEe2cQbEe_UtyT8Pip5d8436M
"""

!python -V
!nvcc --version
!nvidia-smi

import gdown
import os
import random
import torch
import torchvision
from PIL import Image
import torch.nn as nn
from torch.utils.tensorboard import SummaryWriter
from torch.utils.data import DataLoader
import numpy as np
import matplotlib.pyplot as plt
import torch.optim as optim

disc_interation = 5
batch_size = 64
img_size = 64
latent_size = 100
embed_size = 24
learning_rate = 2e-4
Lambda_GP = 10

from google.colab import drive
drive.mount('/content/drive')
file_path = "drive/MyDrive/NYCU/109 Summer Deep Learning and Practice/assignment/[Lab5] Let's play GANs/"

!ls
if os.path.isfile("data.zip"):
  print("file is already exist")
else:
  print("file is not here")
  !gdown --id '1gL6nn0nzBQ-0JIrjIUVygXRqLOCuZWlh' --output data.zip #download data.zip
  !unzip -q data.zip
  print("Done!")

"""#dataset.py"""

import json
import torch
from torch.utils import data
from torchvision import transforms
from PIL import Image
import os
import numpy as np

def get_iCLEVR_data(root_folder,mode):
    if mode == 'train':
        data = json.load(open(os.path.join(root_folder,'train.json')))
        obj = json.load(open(os.path.join(root_folder,'objects.json')))
        img = list(data.keys())
        label = list(data.values())
        for i in range(len(label)):
            for j in range(len(label[i])):
                label[i][j] = obj[label[i][j]]
            tmp = np.zeros(len(obj))
            tmp[label[i]] = 1
            label[i] = tmp
        return np.squeeze(img), np.squeeze(label)
    else:
        data = json.load(open(os.path.join(root_folder,'test.json')))
        obj = json.load(open(os.path.join(root_folder,'objects.json')))
        label = data
        for i in range(len(label)):
            for j in range(len(label[i])):
                label[i][j] = obj[label[i][j]]
            tmp = np.zeros(len(obj))
            tmp[label[i]] = 1
            label[i] = tmp
        return None, label


class ICLEVRLoader(data.Dataset):
    def __init__(self, root_folder, trans=None, cond=False, mode='train'):
        self.root_folder = root_folder
        self.mode = mode
        self.trans = trans
        self.img_list, self.label_list = get_iCLEVR_data(root_folder,mode)
        if self.mode == 'train':
            print("> Found %d images..." % (len(self.img_list)))
        
        self.cond = cond
        self.num_classes = 24
                   
    def __len__(self):
        return len(self.label_list)
        
    def __getitem__(self, index):
        if self.mode == 'train':
          img = self.img_list[index]
          labels = self.label_list[index]        
          if self.trans is not None:
            img_path = "./images/" + self.img_list[index]
            img = Image.open(img_path).convert("RGB")
            img = self.trans(img)

            return img , labels
        else:
          return self.label_list[index]

tfm = transforms.Compose([
    transforms.Resize((img_size,img_size)),
    transforms.ToTensor(),
    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
])

"""#evaluator.py"""

import torch
import torch.nn as nn
import torchvision.models as models

'''===============================================================
1. Title:     

DLP spring 2021 Lab7 classifier

2. Purpose:

For computing the classification accruacy.

3. Details:

The model is based on ResNet18 with only chaning the
last linear layer. The model is trained on iclevr dataset
with 1 to 5 objects and the resolution is the upsampled 
64x64 images from 32x32 images.

It will capture the top k highest accuracy indexes on generated
images and compare them with ground truth labels.

4. How to use

You should call eval(images, labels) and to get total accuracy.
images shape: (batch_size, 3, 64, 64)
labels shape: (batch_size, 24) where labels are one-hot vectors
e.g. [[1,1,0,...,0],[0,1,1,0,...],...]

==============================================================='''


class evaluation_model():
    def __init__(self):
        #modify the path to your own path
        checkpoint = torch.load('classifier_weight.pth')
        self.resnet18 = models.resnet18(pretrained=False)
        self.resnet18.fc = nn.Sequential(
            nn.Linear(512,24),
            nn.Sigmoid()
        )
        self.resnet18.load_state_dict(checkpoint['model'])
        self.resnet18 = self.resnet18.cuda()
        self.resnet18.eval()
        self.classnum = 24
    def compute_acc(self, out, onehot_labels):
        batch_size = out.size(0)
        acc = 0
        total = 0
        for i in range(batch_size):
            k = int(onehot_labels[i].sum().item())
            total += k
            outv, outi = out[i].topk(k)
            lv, li = onehot_labels[i].topk(k)
            for j in outi:
                if j in li:
                    acc += 1
        return acc / total
    def eval(self, images, labels):
        with torch.no_grad():
            #your image shape should be (batch, 3, 64, 64)
            out = self.resnet18(images)
            acc = self.compute_acc(out.cpu(), labels.cpu())
            return acc

"""#Generator & Discriminator"""

# Set random seed for reproducibility
manualSeed = 520
#manualSeed = random.randint(1, 10000) # use if you want new results
print("Random Seed: ", manualSeed)
random.seed(manualSeed)
torch.manual_seed(manualSeed)

# Generator Code

class Generator(nn.Module):
    def __init__(self,
                 num_classes=24,
                 latent_dim=100,
                 num_G_feature=64,
                 num_channels=3,
                 img_size = 64,
                 ):
        super(Generator, self).__init__()
        self.img_size = img_size
        self.num_classes = num_classes
        self.main = nn.Sequential(
            # input is Z, going into a convolution
            # input: N * latent_dim * 1 * 1
        self._block(latent_dim + num_classes, num_G_feature*8, 4, 1, 0),
        self._block(num_G_feature*8, num_G_feature*4, 4, 2, 1),
        self._block(num_G_feature*4, num_G_feature*2, 4, 2, 1),
        self._block(num_G_feature*2, num_G_feature, 4, 2, 1),
        nn.ConvTranspose2d(num_G_feature, num_channels, 4, 2, 1, bias=False),
        nn.Tanh()
        )
        # output: N * num_channels * 64 * 64
    def _block(self, in_channels, out_channels, kernel_size, stride, padding):
      return nn.Sequential(
          nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride, padding, bias=False),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(True),
            
      ) 
    def forward(self, z, labels):
      #latent vector z: N * noise_dim * 1 * 1
      labels = labels.view(-1, self.num_classes, 1, 1)
      #print(z.size(),labels.size())
      x = torch.cat([z, labels], dim=1) # N * C * H * W
      #print(x.size())
      return self.main(x)

'''gen = Generator()
z = torch.randn((64,100,1,1))
label = torch.randn((64,24)).int()
print(gen(z,label).size())'''

class Discriminator(nn.Module):
    def __init__(self,
                 num_channels=3,
                 num_D_feature=64,
                 num_classes=24,
                 img_size=64
                 ):
        super(Discriminator, self).__init__()
        self.img_size = img_size

        self.labels_input = nn.Linear(24, self.img_size*self.img_size)
        self.main = nn.Sequential(
            # input is (nc) x 64 x 64
            # in_channels, out_channels, kernel_size:, stride, padding
            nn.Conv2d(num_channels+1, num_D_feature, 4, 2, 1, bias=False),
            nn.LeakyReLU(0.2),
            # state size. (ndf) x 32 x 32
            self._block(num_D_feature, num_D_feature * 2, 4, 2, 1),
            # state size. (ndf*2) x 16 x 16
            self._block(num_D_feature * 2, num_D_feature * 4, 4, 2, 1),
            # state size. (ndf*4) x 8 x 8
            self._block(num_D_feature * 4, num_D_feature * 8, 4, 2, 1),
            # state size. (ndf*8) x 4 x 4
            nn.Conv2d(num_D_feature * 8, 1, 4, 2, 0, bias=False),
            #nn.Sigmoid()
        )
    def _block(self, in_channels, out_channels, kernel_size, stride, padding):
      return nn.Sequential(
          nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding, bias=False),
          nn.InstanceNorm2d(out_channels, affine=True),
          nn.LeakyReLU(0.2),
      )
    def forward(self, x, labels):
        labels = self.labels_input(labels).view(-1,1,self.img_size,self.img_size)
        #print(x.size(),labels.size())
        x = torch.cat([x, labels],dim=1) # N * C * H * W
        
        #print(x.size())
        return self.main(x)

'''disc = Discriminator()
x = torch.randn((1,3,64,64))
labels = torch.randn((24))
print(disc(x,labels))'''

def save_model(model,model_name):
  FILE = file_path + "model/" + str(model_name) + ".pth"
  torch.save(model.state_dict(), FILE)

def load_model(model,model_name):
  device = "cuda" if torch.cuda.is_available() else "cpu"
  FILE = file_path + "4/model/" + str(model_name) + ".pth"
  model.load_state_dict(torch.load(FILE))
  model.to(device)

def Demo():
  for labels in test_loader:
    noise = torch.randn(32, latent_size, 1, 1).to(device)
    labels = labels.float().to(device)
    img = gen(noise,labels)
    acc = eva.eval(img,labels)
    print(acc)

def initialize_weights(model):
    # Initializes weights according to the DCGAN paper
    for m in model.modules():
        if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d, nn.BatchNorm2d)):
            nn.init.normal_(m.weight.data, 0.0, 0.02)

def gradient_penalty(critic, labels, real, fake, device="cpu"):
    BATCH_SIZE, C, H, W = real.shape
    alpha = torch.rand((BATCH_SIZE, 1, 1, 1)).repeat(1, C, H, W).to(device)
    interpolated_images = real * alpha + fake * (1 - alpha)

    # Calculate critic scores
    mixed_scores = critic(interpolated_images,labels)

    # Take the gradient of the scores with respect to the images
    gradient = torch.autograd.grad(
        inputs=interpolated_images,
        outputs=mixed_scores,
        grad_outputs=torch.ones_like(mixed_scores),
        create_graph=True,
        retain_graph=True,
    )[0]
    gradient = gradient.view(gradient.shape[0], -1)
    gradient_norm = gradient.norm(2, dim=1)
    gradient_penalty = torch.mean((gradient_norm - 1) ** 2)
    return gradient_penalty

"""#Trainer"""

def WGAN_GP_train(gen,disc,epochs):
  gen.train()
  disc.train()

  #G_loss_array = []
  #D_loss_array = []
  test_acc_array = []

  fixed_noise = torch.randn(32,latent_size,1,1).to(device)
  writer_real = SummaryWriter(file_path + f"logs/real")
  writer_fake = SummaryWriter(file_path + f"logs/fake")
  writer_test = SummaryWriter(file_path + f"logs/test")
  writer = SummaryWriter(file_path + f"logs/scales")
  
  step = 0
  print("-----------------strat-----------------")
  for epoch in range(epochs):
    print(f"epoch [{epoch}/{epochs}]")

    for batch_idx , batch in enumerate(train_loader):
      img , labels = batch
      labels = labels.float().to(device)
      real_img = img.to(device)
      cur_batch_size = real_img.shape[0]

      if epoch == 0 and batch_idx == 1:
        fixed_labels = labels[:32]
        fixed_real_img = real_img[:32]
        #print(fixed_labels.size())



      for _ in range(disc_interation):
        noise = torch.randn(cur_batch_size, latent_size, 1, 1).to(device)

        fake_img = gen(noise, labels)
        disc_real = disc(real_img, labels).reshape(-1)
        disc_fake = disc(fake_img, labels).reshape(-1)

        gp = gradient_penalty(disc, labels,real_img, fake_img, device)
        loss_disc = ( -( torch.mean(disc_real) - torch.mean(disc_fake))
                  + Lambda_GP * gp )
        
        disc.zero_grad()
        loss_disc.backward(retain_graph=True)
        optim_disc.step()

      gen_fake = disc(fake_img, labels).view(-1)
      loss_gen = -torch.mean(gen_fake)
      gen.zero_grad()
      loss_gen.backward()
      optim_gen.step()


      if batch_idx % 30 == 0 and batch_idx > 0:
        print(f"Epoch [{epoch}/{epochs}] Batch {batch_idx}/{len(train_loader)} \
        Loss D: {loss_disc:.4f}, Loss G: {loss_gen:.4f}")

        with torch.no_grad():
          fake_img = gen(fixed_noise,fixed_labels)
          
          img_grid_fake = torchvision.utils.make_grid(fake_img[:32],normalize=True)

          if step == 0:
            img_grid_real = torchvision.utils.make_grid(fixed_real_img[:32],normalize=True)
            torchvision.utils.save_image(img_grid_real,
                                       file_path + "image/"+"fixed_real_img"+".png",)

          torchvision.utils.save_image(img_grid_fake,
                                       file_path + "image/fake_img_"+str(step)+".png")

          #G_loss_array.append(loss_gen)
          #D_loss_array.append(loss_disc)

          for labels in test_loader:
            noise = torch.randn(32, latent_size, 1, 1).to(device)
            labels = labels.float().to(device)
            img = gen(noise,labels)
            acc = eva.eval(img,labels)
            #test_acc_array.append(acc)

            img_grid_test = torchvision.utils.make_grid(img,normalize=True)
            torchvision.utils.save_image(img_grid_test,
                                       file_path + "test/test_img_"+str(step)+".png")
            writer.add_scalar('test_acc', acc, global_step = step )
            print(f"Epoch [{epoch}/{epochs}] Step[{step}]  test_acc: {acc:.4f}" )
          
          writer_real.add_image("Real", img_grid_real, global_step = step )
          writer_fake.add_image("Fake", img_grid_fake, global_step = step )
          writer_test.add_image("Test", img_grid_test, global_step = step )
          writer.add_scalar('G_loss', loss_gen, global_step = step )
          writer.add_scalar('D_loss', loss_disc, global_step = step )
          
          step += 1

    
    print(f"save mode_{str(epoch +1)}")
    save_model(gen, "gen_" + str(epoch +1) )
    save_model(disc, "disc_" + str(epoch +1) )

"""#Tensorboard"""

# Commented out IPython magic to ensure Python compatibility.
# %load_ext tensorboard
from tensorboard import notebook
notebook.list() # View open TensorBoard instances
# Control TensorBoard display. If no port is provided, 
# the most recently launched TensorBoard is used
'''notebook.display(port=6006, height=800)

notebook.display(port=6007, height=800)'''

# %tensorboard --logdir "drive/MyDrive/NYCU/109 Summer Deep Learning and Practice/assignment/[Lab5] Let's play GANs/logs/"

"""#main"""

device = "cuda" if torch.cuda.is_available() else "cpu"
disc_interation = 5
batch_size = 128
img_size = 64
latent_size = 100
embed_size = 24
learning_rate = 2e-4
Lambda_GP = 10

TrainDataset = ICLEVRLoader("./",mode="train",trans=tfm)
TestDataset = ICLEVRLoader("./",mode="test",trans=tfm)

train_loader = DataLoader(TrainDataset, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)
test_loader = DataLoader(TestDataset, batch_size=32, shuffle=False, num_workers=2, pin_memory=True)

eva = evaluation_model()

gen = Generator().to(device)
disc = Discriminator().to(device)

'''initialize_weights(gen)
initialize_weights(disc)'''

optim_gen = optim.Adam(gen.parameters(), lr=learning_rate, betas=(0.0,0.9) )
optim_disc = optim.Adam(disc.parameters(), lr=learning_rate, betas=(0.0,0.9) )



load_model(gen,"gen_50")
load_model(disc,"disc_50")

WGAN_GP_train(gen,disc,epochs=100)

